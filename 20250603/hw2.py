# -*- coding: utf-8 -*-
"""
This script retrieves bus stop data for all route IDs listed in route_name_code.csv,
fetches the "go" direction stops, and saves all routes' stops to a single CSV file in a horizontal format.
"""
import os
import pandas as pd
import requests
from bs4 import BeautifulSoup


class taipei_route_info:
    """
    Manages fetching, parsing, and storing bus stop data for a specified route and direction.
    """
    def __init__(self, route_id: str, direction: str = 'go', working_directory: str = 'data'):
        self.route_id = route_id
        self.direction = direction
        self.content = None
        self.url = f'https://ebus.gov.taipei/Route/StopsOfRoute?routeid={route_id}'
        self.working_directory = working_directory
        self.html_file = f"{self.working_directory}/ebus_taipei_{self.route_id}.html"

        # ç¢ºä¿è³‡æ–™å¤¾å­˜åœ¨
        if not os.path.exists(self.working_directory):
            os.makedirs(self.working_directory)
            print(f"âœ… Created working directory: {self.working_directory}")

        # å¦‚æœæª”æ¡ˆä¸å­˜åœ¨ï¼ŒæŠ“å– HTML
        if not os.path.exists(self.html_file):
            self.fetch_html()

        # è®€å– HTML æª”æ¡ˆ
        with open(self.html_file, 'r', encoding='utf-8') as file:
            self.content = file.read()

    def fetch_html(self):
        """
        Fetches the HTML content for the specified route ID and saves it to a file.
        """
        response = requests.get(self.url)
        if response.status_code == 200:
            with open(self.html_file, 'w', encoding='utf-8') as file:
                file.write(response.text)
            print(f"âœ… Fetched and saved HTML for route {self.route_id}")
        else:
            print(f"âŒ Failed to fetch HTML for route {self.route_id}. Status code: {response.status_code}")
            raise Exception(f"Failed to fetch HTML for route {self.route_id}. Status code: {response.status_code}")

    def parse_stations(self) -> list:
        """
        Parses station names from the HTML content for the specified route and direction.
        """
        soup = BeautifulSoup(self.content, 'html.parser')
        
        # æ ¹æ“šæ–¹å‘é¸æ“‡æ­£ç¢ºçš„å€å¡Š
        if self.direction == 'go':
            route_div = soup.find('div', id='GoDirectionRoute')
        else:
            raise ValueError("This script only supports 'go' direction.")

        if not route_div:
            print(f"âŒ No route data found for direction {self.direction}.")
            return []

        # æå–è»Šç«™åç¨±
        station_names = []
        for station in route_div.find_all('span', class_='auto-list-stationlist-place'):
            station_names.append(station.text.strip())

        return station_names


if __name__ == "__main__":
    # è®€å– route_name_code.csv
    csv_file_path = "c:/Users/User/Desktop/cycu_oop_11372006/data/route_name_code.csv"
    output_csv_path = "c:/Users/User/Desktop/cycu_oop_11372006/20250603/all_routes_horizontal.csv"

    # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
    output_directory = os.path.dirname(output_csv_path)
    if not os.path.exists(output_directory):
        os.makedirs(output_directory)

    # è®€å– CSV æª”æ¡ˆ
    route_data = pd.read_csv(csv_file_path, header=None, names=["RouteName", "RouteID"], encoding="utf-8-sig")

    # åˆå§‹åŒ–ä¸€å€‹ç©ºçš„åˆ—è¡¨ï¼Œç”¨æ–¼å­˜æ”¾æ‰€æœ‰è·¯ç·šçš„è³‡æ–™
    all_routes_data = []

    # éæ­·æ¯å€‹å…¬è»Šä»£ç¢¼
    for _, row in route_data.iterrows():
        route_name = row["RouteName"]
        route_id = row["RouteID"]

        print(f"ğŸ” æ­£åœ¨è™•ç†å…¬è»Šè·¯ç·š: {route_name} (ID: {route_id})")

        try:
            # åˆå§‹åŒ– taipei_route_info ä¸¦æŠ“å–ç«™é»è³‡æ–™
            route_info = taipei_route_info(route_id=route_id, direction="go", working_directory="data")
            station_names = route_info.parse_stations()

            # å¦‚æœæœ‰ç«™é»è³‡æ–™ï¼Œå°‡å…¶åŠ å…¥åˆ°åˆ—è¡¨
            if station_names:
                row_data = [route_name, route_id] + station_names
                all_routes_data.append(row_data)
            else:
                print(f"âŒ No station data found for route {route_name} (ID: {route_id})")
        except Exception as e:
            print(f"âŒ ç„¡æ³•è™•ç†å…¬è»Šè·¯ç·š {route_name} (ID: {route_id})ï¼ŒéŒ¯èª¤: {e}")

    # å°‡æ‰€æœ‰è·¯ç·šçš„è³‡æ–™è½‰æ›ç‚º DataFrame
    max_columns = max(len(row) for row in all_routes_data)  # æ‰¾å‡ºæœ€å¤šçš„ç«™é»æ•¸é‡
    column_names = ["RouteName", "RouteID"] + [f"Station{i}" for i in range(1, max_columns - 1)]
    all_routes_df = pd.DataFrame(all_routes_data, columns=column_names)

    # å°‡æ‰€æœ‰è·¯ç·šçš„è³‡æ–™ä¿å­˜åˆ°å–®ä¸€çš„ CSV æª”æ¡ˆ
    all_routes_df.to_csv(output_csv_path, index=False, encoding='utf-8-sig')
    print(f"âœ… æ‰€æœ‰è·¯ç·šçš„ç«™é»è³‡æ–™å·²ä¿å­˜åˆ° {output_csv_path}")
